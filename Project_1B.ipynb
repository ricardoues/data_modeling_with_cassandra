{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_query(query, type_query, row=()):\n",
    "    \"\"\"Run a query in Apache Cassandra.\n",
    "    \n",
    "    Parameters:        \n",
    "       query (string): the string of the query. \n",
    "       type_query (string): the type of query: select, create or drop.\n",
    "       row (tuple): a tuple to be inserted. \n",
    "    \n",
    "    Returns: \n",
    "        None if the function executes a select or drop operation, \n",
    "        a result set if the function executes  .\n",
    "    \"\"\" \n",
    "    \n",
    "    if type_query == \"insert\":\n",
    "        try:\n",
    "            rows = session.execute(query, row)\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(e)        \n",
    "        \n",
    "    elif type_query == \"select\":\n",
    "        try:\n",
    "            rows = session.execute(query)\n",
    "            return rows \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            session.execute(query)\n",
    "            return None \n",
    "        except Exception as e:   \n",
    "            print(e)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_filepaths():\n",
    "    \"\"\"Create the list of filepaths to process original \n",
    "       event csv data files.\n",
    "    \n",
    "    Parameters:        \n",
    "       Nothing, this function does not have parameters. \n",
    "    \n",
    "    Returns: \n",
    "        file_path_list (list): a list of filepaths.\n",
    "    \"\"\" \n",
    "    \n",
    "    \n",
    "    # Get your current folder and subfolder event data\n",
    "    filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "    # Create a for loop to create a list of files and collect each filepath\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        # join the file path and roots with the subdirectories using glob\n",
    "        file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "        \n",
    "    return file_path_list        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_path_list = process_filepaths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_files(file_path_list, output_file):\n",
    "    \"\"\"Process the files to create the data file csc that will be used \n",
    "       for Apacha Cassandra tables.\n",
    "    \n",
    "    Parameters:        \n",
    "       file_path_list (list): a list of filepaths. \n",
    "       output_file (string): the name of the csv file that will be used for\n",
    "                             Apache Cassandra.\n",
    "    \n",
    "    Returns: \n",
    "        None, the function simply processes files and creates a csv file.\n",
    "    \"\"\" \n",
    "    \n",
    "    # initiating an empty list of rows that will be generated from each file\n",
    "    full_data_rows_list = [] \n",
    "\n",
    "    \n",
    "    # for every filepath in the file path list \n",
    "    for f in file_path_list:\n",
    "        # reading csv file \n",
    "        with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "            # creating a csv reader object \n",
    "            csvreader = csv.reader(csvfile) \n",
    "            next(csvreader)\n",
    "        \n",
    "            # extracting each data row one by one and append it        \n",
    "            for line in csvreader:\n",
    "                full_data_rows_list.append(line) \n",
    "            \n",
    "    # creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "    # Apache Cassandra tables\n",
    "    csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "    with open(output_file, 'w', encoding = 'utf8', newline='') as f:\n",
    "        writer = csv.writer(f, dialect='myDialect')\n",
    "        writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "        for row in full_data_rows_list:\n",
    "            if (row[0] == ''):\n",
    "                continue\n",
    "            writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "process_files(file_path_list, 'event_datafile_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"artist\",\"firstName\",\"gender\",\"itemInSession\",\"lastName\",\"length\",\"level\",\"location\",\"sessionId\",\"song\",\"userId\"\n",
      "\"Stephen Lynch\",\"Jayden\",\"M\",\"0\",\"Bell\",\"182.85669\",\"free\",\"Dallas-Fort Worth-Arlington, TX\",\"829\",\"Jim Henson's Dead\",\"91\"\n",
      "\"Manowar\",\"Jacob\",\"M\",\"0\",\"Klein\",\"247.562\",\"paid\",\"Tampa-St. Petersburg-Clearwater, FL\",\"1049\",\"Shell Shock\",\"73\"\n",
      "\"Morcheeba\",\"Jacob\",\"M\",\"1\",\"Klein\",\"257.41016\",\"paid\",\"Tampa-St. Petersburg-Clearwater, FL\",\"1049\",\"Women Lose Weight (Feat: Slick Rick)\",\"73\"\n",
      "\"Maroon 5\",\"Jacob\",\"M\",\"2\",\"Klein\",\"231.23546\",\"paid\",\"Tampa-St. Petersburg-Clearwater, FL\",\"1049\",\"Won't Go Home Without You\",\"73\"\n",
      "\"Train\",\"Jacob\",\"M\",\"3\",\"Klein\",\"216.76363\",\"paid\",\"Tampa-St. Petersburg-Clearwater, FL\",\"1049\",\"Hey_ Soul Sister\",\"73\"\n",
      "\"LMFAO\",\"Jacob\",\"M\",\"4\",\"Klein\",\"227.99628\",\"paid\",\"Tampa-St. Petersburg-Clearwater, FL\",\"1049\",\"I'm In Miami Bitch\",\"73\"\n",
      "\"DJ Dizzy\",\"Jacob\",\"M\",\"5\",\"Klein\",\"221.1522\",\"paid\",\"Tampa-St. Petersburg-Clearwater, FL\",\"1049\",\"Sexy Bitch\",\"73\"\n",
      "\"Fish Go Deep & Tracey K\",\"Jacob\",\"M\",\"6\",\"Klein\",\"377.41669\",\"paid\",\"Tampa-St. Petersburg-Clearwater, FL\",\"1049\",\"The Cure & The Cause (Dennis Ferrer Remix)\",\"73\"\n",
      "\"M83\",\"Jacob\",\"M\",\"7\",\"Klein\",\"96.1824\",\"paid\",\"Tampa-St. Petersburg-Clearwater, FL\",\"1049\",\"Staring At Me\",\"73\"\n"
     ]
    }
   ],
   "source": [
    "! head event_datafile_new.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Apache Cassandra coding section. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS udacity\n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1} \"\"\"\n",
    ")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Task 1: Getting the artist, song title and song's length in the music app history that was heard during sessionId = 338, and itemInSession = 4.\n",
    "\n",
    "For this query itemInSession and sessionId are considered as the composite key, because this query was thought to recover values for sessionId and itemInSession. SessionId is the partition key and its role is to spread data evenly around the cluster. ItemInSession is a cluster column which allows to sort the data. From the above, we meet the requirements of the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query1 = \"CREATE TABLE IF NOT EXISTS song_information \"\n",
    "query1 = query1 + \" (session_id int, item_in_session int, \\\n",
    "                     artist text, \\\n",
    "                     song_title text, \\\n",
    "                     song_length float, \\\n",
    "                     PRIMARY KEY (session_id, item_in_session))\"\n",
    "\n",
    "run_query(query1, \"create\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_information (session_id, item_in_session, \\\n",
    "                 artist, song_title, song_length)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        run_query(query, \"insert\", (int(line[8]), int(line[3]), line[0], line[9],float(line[5])) )        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist: Faithless, Song Title: Music Matters (Mark Knight Dub), Song Length: 495.30731201171875\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT artist, song_title, song_length FROM song_information \"\n",
    "query = query + \"WHERE session_id = 338 AND item_in_session = 4\"\n",
    "try:\n",
    "    rows = run_query(query, \"select\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print(\"Artist: {}, Song Title: {}, Song Length: {}\".format\n",
    "          (row.artist, row.song_title, row.song_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Task 2: Getting the the name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182.\n",
    "\n",
    "For this query userId, sessionId, itemInSession  are considered as the composite key. UserId and SessionId are a composite partition key and its role is to spread data evenly around the cluster. ItemInSession is a cluster column which allows to sort the data. From the above, we meet the requirements of the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query2 = \"CREATE TABLE IF NOT EXISTS activity_information \"\n",
    "query2 = query2 + \" (user_id int, session_id int, item_in_session int, \\\n",
    "                     artist text, \\\n",
    "                     song_title text, \\\n",
    "                     first_name_user text, \\\n",
    "                     last_name_user text, \\\n",
    "                     PRIMARY KEY ((user_id, session_id), item_in_session))\"\n",
    "\n",
    "run_query(query2, \"create\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO activity_information (user_id, \\\n",
    "                 session_id, item_in_session, \\\n",
    "                 artist, song_title, \\\n",
    "                 first_name_user, last_name_user \\\n",
    "                 )\"        \n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        run_query(query, \"insert\", (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist: Down To The Bone, Song Title: Keep On Keepin' On,            first_name_user: Sylvie, last_name_user: Cruz\n",
      "Artist: Three Drives, Song Title: Greece 2000,            first_name_user: Sylvie, last_name_user: Cruz\n",
      "Artist: Sebastien Tellier, Song Title: Kilometer,            first_name_user: Sylvie, last_name_user: Cruz\n",
      "Artist: Lonnie Gordon, Song Title: Catch You Baby (Steve Pitron & Max Sanna Radio Edit),            first_name_user: Sylvie, last_name_user: Cruz\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT artist, song_title, first_name_user, last_name_user \\\n",
    "         FROM activity_information \"\n",
    "query = query + \"WHERE user_id = 10 AND session_id = 182\"\n",
    "try:\n",
    "    rows = run_query(query, \"select\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print(\"Artist: {}, Song Title: {}, \\\n",
    "           first_name_user: {}, last_name_user: {}\".format(row.artist, \n",
    "           row.song_title, row.first_name_user, row.last_name_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Task3: Getting every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "For this query songTitle and userId are considered as the composite key. SongTitle is the partition key and its role is to spread data evenly around the cluster. UserId is a cluster column which allows to sort the data. We have to include userId since the combination of first and last name could not be unique. We suppose that the userId is greater than 0. From the above, we meet the requirements of the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query3 = \"CREATE TABLE IF NOT EXISTS user_song_information \"\n",
    "query3 = query3 + \" (song_title text, \\\n",
    "                     user_id int, \\\n",
    "                     first_name_user text, \\\n",
    "                     last_name_user text, \\\n",
    "                     PRIMARY KEY (song_title, user_id))\"\n",
    "\n",
    "try:\n",
    "    run_query(query3, \"create\")\n",
    "except Exception as e:\n",
    "    print(e)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Cassandra is optimized for writes that is why we do not care about if we will insert the same item, cassandra simply will replace it \n",
    "\n",
    "https://medium.com/coinmonks/cassandra-distributed-key-value-store-optimized-for-write-heavy-workloads-77f69c01388c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_song_information (song_title, user_id, \\\n",
    "                 first_name_user, \\\n",
    "                 last_name_user)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s)\"\n",
    "        run_query(query, \"insert\", (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_name_user: Jacqueline, last_name_user: Lynch\n",
      "first_name_user: Tegan, last_name_user: Levine\n",
      "first_name_user: Sara, last_name_user: Johnson\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT first_name_user, last_name_user \\\n",
    "         FROM user_song_information \"\n",
    "query = query + \"WHERE song_title = 'All Hands Against His Own' AND user_id > 0\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print(\"first_name_user: {}, last_name_user: {}\".format\n",
    "          (row.first_name_user, row.last_name_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = \"drop table song_information\"\n",
    "run_query(query, \"drop\")\n",
    "\n",
    "query = \"drop table activity_information\"\n",
    "run_query(query, \"drop\")\n",
    "    \n",
    "query = \"drop table user_song_information\"\n",
    "run_query(query, \"drop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
